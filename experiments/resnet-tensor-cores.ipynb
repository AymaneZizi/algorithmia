{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils import data\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms.functional as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm \n",
    "device = torch.device(1)\n",
    "%matplotlib\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, list_images, labels, folder_name =\"./\"):\n",
    "        self.list_images = list_images\n",
    "        self.labels = labels\n",
    "        self.folder_name = folder_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len (self.list_images)\n",
    "    \n",
    "    def __load_images__(self, image_file_name ):\n",
    "        img = Image.open(os.path.join(self.folder_name,image_file_name)).resize((224, 224), resample=0)\n",
    "        img = torch.Tensor((np.asarray(img).transpose(2,0,1))/255.0)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_batch = self.__load_images__(self.list_images[index])\n",
    "        label = self.labels[index]\n",
    "        return file_batch, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_list = os.listdir(\"data/train/\")\n",
    "labels = []\n",
    "for i in image_list:\n",
    "    if i[:3] == 'dog':\n",
    "        labels.append([1,0])\n",
    "    else:\n",
    "        labels.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = Dataset(image_list, labels, folder_name=\"data/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "for fn, label in training_generator:\n",
    "    print(fn.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3,stride=stride, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, BasicBlock, layers, num_classes=2):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 , num_classes)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def _make_layer(self, BasicBlock, planes, num_blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.inplanes, planes,kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes))\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)    # 224x224\n",
    "        x = self.bn1(x)     \n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)  # 112x112\n",
    "\n",
    "        x = self.layer1(x)   # 56x56\n",
    "        x = self.layer2(x)   # 28x28\n",
    "        x = self.layer3(x)   # 14x14\n",
    "        x = self.layer4(x)   # 7x7\n",
    "\n",
    "        x = self.avgpool(x)  # 1x1\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.tanh (self.fc(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet34(**kwargs):\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = resnet34().to(device).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_accuracy(predicted , gold ):\n",
    "    predicted_argmax = torch.argmax(input=predicted, dim=1)\n",
    "    gold_argmax = torch.argmax(input=gold, dim=1)\n",
    "    correct = (predicted_argmax == gold_argmax)\n",
    "    accuracy = float(sum(correct))/ len(gold_argmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_param_list(model:torch.nn.Module):\n",
    "    model_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    master_params = [p.detach().clone().float() for p  in model.parameters()]\n",
    "    for p in model_params:\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    return model_params, master_params\n",
    "\n",
    "def master_param_to_model_param(model_param, master_param):\n",
    "    for model, master in zip(model_param, master_param):\n",
    "        model.data.copy_(master.data)\n",
    "        \n",
    "def model_grad_to_master_grad(model_param, master_param):\n",
    "    for model, master in zip(model_param, master_param):\n",
    "        if master.grad is None:\n",
    "            master.grad = torch.autograd.Variable(master.data.new(*master.data.size()))\n",
    "    master.grad.data.copy_(model.grad.data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params, master_params = pre_param_list(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criteria = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(master_params,lr=0.0001,momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_BN_to_float(module):\n",
    "    if  isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.float()\n",
    "    for child in module.children():\n",
    "        convert_BN_to_float(child)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in model.modules():\n",
    "    convert_BN_to_float(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [15:34<07:59, 28.19s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6007b895d8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel_grad_to_master_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaster_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscaled_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/sunil.patel/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rdiv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreciprocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreciprocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scale_factor  = 128\n",
    "writer = SummaryWriter()\n",
    "total_updates= 0 \n",
    "for epoch_no in tqdm(range(50)):\n",
    "    for fn, label in training_generator:\n",
    "        optimizer.zero_grad()\n",
    "        predict = model(fn.to(device).half())\n",
    "        loss = criteria(predict.to(device).float(), label.half().to(device).float())\n",
    "        scaled_loss = loss.float() * scale_factor\n",
    "#         print(predict)\n",
    "\n",
    "        scaled_loss.backward()\n",
    "        model_grad_to_master_grad(model_params, master_params)\n",
    "        for p in master_params:\n",
    "            p.grad.data.mul_(1./scaled_loss)\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        master_param_to_model_param(model_params, master_params)\n",
    "        accuracy = get_binary_accuracy(predict.type(torch.FloatTensor).cpu(), label)\n",
    "        writer.add_scalar('Train/loss_1_GPU_TC', loss,total_updates )\n",
    "        writer.add_scalar('Train/accuracy_1_GPU_TC', accuracy,total_updates )\n",
    "        total_updates = total_updates + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for each_layer in resnet.state_dict():\n",
    "    print(each_layer,\"\\t\", resnet.state_dict()[each_layer].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

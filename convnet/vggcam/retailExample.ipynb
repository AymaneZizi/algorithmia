{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import theano\n",
    "from scipy.misc import imread, imresize, imsave\n",
    "import keras\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from scipy.misc import imread, imresize, imsave\n",
    "from keras.layers.core import Flatten, Dense, Dropout,Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D,UpSampling2D,UpSampling1D,Cropping2D\n",
    "from keras.optimizers import SGD\n",
    "# %matplotlib inline\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.preprocessing import normalize\n",
    "import traceback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import ndimage\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras import callbacks\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "import warnings\n",
    "from shutil import copyfile\n",
    "import theano.tensor.nnet.abstract_conv as absconv\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageResize(imagePath):\n",
    "    \"\"\"\n",
    "    resize image\n",
    "    basename : eg. /home/username/XYZFolder\n",
    "    image name : xyz.jpg\n",
    "    New folder in the working directory will be created with '_resized' as suffix\n",
    "    \"\"\"\n",
    "    imagePathsplitted = imagePath.split(\"/\")\n",
    "    new_width  = 224\n",
    "    new_height = 224\n",
    "    try:\n",
    "        img = Image.open(imagePath) # image extension *.png,*.jpg\n",
    "        img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "        img.save('img_resized/'+imagePathsplitted[1]+\"/\"+imagePathsplitted[2])\n",
    "    except:\n",
    "        os.mkdir('img_resized/'+imagePathsplitted[1]+\"/\")\n",
    "        img = Image.open(imagePath) # image extension *.png,*.jpg\n",
    "        img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "        img.save('img_resized/' + imagePathsplitted[1] + \"/\" + imagePathsplitted[2])\n",
    "\n",
    "def resizeAll():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    fileIn = open(\"Anno/list_category_img.txt\").read().splitlines()\n",
    "    for imageAndCategoryLineNo in range(0,len(fileIn)):\n",
    "        try:\n",
    "            imagePath =  fileIn[imageAndCategoryLineNo].split(\" \")[0]\n",
    "            # category = imageAndCategory.split(\" \")[-1]\n",
    "            imagePath =  imagePath.strip()\n",
    "            # category = int(category.strip())\n",
    "            print imageAndCategoryLineNo\n",
    "            imageResize(imagePath)\n",
    "        except:\n",
    "            print imageAndCategoryLineNo,\"ERROR ENCOUNTERED\"\n",
    "            \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resizeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    \"\"\"\n",
    "    Function to load image to ram as in form of numpy data.\n",
    "    \"\"\"\n",
    "    img = ndimage.imread( infilename )\n",
    "    data = np.asarray( img, dtype=\"int16\" )\n",
    "    resized = data.reshape(data.shape[2],data.shape[0],data.shape[1])\n",
    "    resized = resized/255.0\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining number of classes under consideration\n",
    "uniqueClassNames = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImageAndCategory(batchSize):\n",
    "    \"\"\"\n",
    "    to get an image loaded in to ram along with its category\n",
    "    usage : image,labels = getImageAndCategory(10) # use iterator\n",
    "    test: \n",
    "    i = 0\n",
    "    for image,labels in getImageAndCategory(10):\n",
    "        print image.shape,labels.shape\n",
    "        i = i + 1\n",
    "        if i == 5:\n",
    "            break\n",
    "    \"\"\"\n",
    "    fileIn = list(set(open(\"Anno/new_category_img.txt\").read().splitlines()))# set will shuffle all lines in files, good for ML with minibatch \n",
    "    print \"TOTAL FILES IN  EXPERIMETNS ARE : \", len(fileIn)\n",
    "    for batchNo in range(0,len(fileIn)/batchSize):\n",
    "        imagePaths = fileIn[batchNo*batchSize:(batchNo+1)*batchSize]\n",
    "        images = []\n",
    "        labels = []\n",
    "        for imageAndCategoryLineNo in range (0,len(imagePaths)):  \n",
    "            try:\n",
    "                singleImagePathAndCategory =  imagePaths[imageAndCategoryLineNo].split(\" \")\n",
    "                category = singleImagePathAndCategory[-1].strip()\n",
    "                singleImagePath = singleImagePathAndCategory[0].strip()\n",
    "                singleImagePath = singleImagePath.replace(\"img/\",\"img_resized/\")\n",
    "                images.append(load_image(singleImagePath))\n",
    "                category = int(category)\n",
    "                labels.append(category)\n",
    "            except:\n",
    "                print traceback.print_exc()\n",
    "                print \"ERROR ENCOUNTERED\"\n",
    "        yield np.asarray(images, dtype='float16'),np.asarray(np_utils.to_categorical(np.asarray(labels),uniqueClassNames),dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModelDefination(trainedModelPath=None):\n",
    "        \"\"\"\n",
    "        core definition of model\n",
    "        :return: compiled model\n",
    "        \"\"\"\n",
    "        # defining convolutional network\n",
    "        model = Sequential()\n",
    "        model.add(ZeroPadding2D((1, 1), input_shape=(3, 224, 224)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(64,  3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128,  3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256,  3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512,  3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512,  3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        # compiling model\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        # returning Model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_test_images(epochNo,batch_Count,image_numpy, actual_label, predicted_label):\n",
    "    \"\"\"\n",
    "    to cheack prediction of model on given 10 images while training\n",
    "    \"\"\"\n",
    "    for eachImageno in range(0,len(image_numpy)):\n",
    "        shape_of_image =  image_numpy[eachImageno].shape\n",
    "        # writing an image with epochNo_acualclass_predictedClass.jpg\n",
    "        imsave('inline_validation/'+str(epochNo)+\"_\"+str(batch_Count)+\"_\"+str(list(actual_label[eachImageno]).index(True))+\"_\"+str(predicted_label[eachImageno])+\".jpg\", image_numpy[eachImageno].reshape(shape_of_image[1],shape_of_image[2],shape_of_image[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Defining model with larger pulling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGGCAM(nb_classes, num_input_channels):\n",
    "    \"\"\"\n",
    "    Build Convolution Neural Network\n",
    "    nb_classes : nb_classes (int) number of classes\n",
    "    num_input_channels : number of channel to be kept in last convolutional model of VGGCAM\n",
    "    returns : Neural Net model\n",
    "    \"\"\"\n",
    "    VGGCAM = Sequential()\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1), input_shape=(3, 224, 224)))\n",
    "    VGGCAM.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    VGGCAM.add(ZeroPadding2D((1, 1)))\n",
    "    VGGCAM.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "\n",
    "    # Add another conv layer with ReLU + GAP\n",
    "    VGGCAM.add(Convolution2D(num_input_channels, 3, 3, activation='relu', border_mode=\"same\"))\n",
    "    VGGCAM.add(AveragePooling2D((14, 14)))\n",
    "    VGGCAM.add(Flatten())\n",
    "    # Add the W layer\n",
    "    VGGCAM.add(Dense(nb_classes, activation='softmax'))\n",
    "#     VGGCAM.summary()\n",
    "    return VGGCAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning VGG Model with specialized train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_VGGCAM(trained_weight_path, nb_classes,epoches,batchSize, num_input_channels):\n",
    "    \"\"\"\n",
    "    Train VGG model\n",
    "    args: VGG_weight_path (str) path to keras vgg16 weights\n",
    "          nb_classes (int) number of classes\n",
    "          num_input_channels (int) number of conv filters to add\n",
    "                                   in before the GAP layer\n",
    "    \"\"\"\n",
    "\n",
    "    # Load model\n",
    "    trainedModel = getModelDefination(trainedModelPath=trained_weight_path)\n",
    "\n",
    "    # Compile\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    trainedModel.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    for epochNo in range(0,epoches):\n",
    "        print \"Epoch No : \", epochNo\n",
    "        batch_Count = 0\n",
    "        for image,labels in getImageAndCategory(batchSize):\n",
    "            try:\n",
    "                # last 10 image selection for test while training\n",
    "                # train model with rest images\n",
    "                for i in range (len(trainedModel.layers)):\n",
    "                    print (i, trainedModel.layers[i].name),\n",
    "                print \"\\n\"+\"%\"*100\n",
    "                trainedModel.fit(image,labels,batch_size=50,nb_epoch=1, verbose=1)\n",
    "                modelCAM = VGGCAM(nb_classes,num_input_channels)\n",
    "                print (\"NAME OF LAYERS IN NEW MODEL FOR CAM\")\n",
    "                for i in range (len(modelCAM.layers)):\n",
    "                    print (i, modelCAM.layers[i].name),\n",
    "\n",
    "                # Load weights to new model\n",
    "                for k in range(len(trainedModel.layers)):\n",
    "                    weights = trainedModel.layers[k].get_weights()\n",
    "                    modelCAM.layers[k].set_weights(weights)\n",
    "            #        modelCAM.layers[k].trainable=True\n",
    "                    if k==16:\n",
    "                        break\n",
    "                print('\\nModel loaded.')\n",
    "                batch_Count = batch_Count + 1\n",
    "                modelCAM.save_weights(\"CAM_Trained.h5\")\n",
    "                # to see performance of model on one of the image while training \n",
    "                plot_classmap(\"CAM_Trained.h5\",trainedModel, \"jeans.jpg\", 1,nb_classes,num_input_channels)\n",
    "            except:\n",
    "                print traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classmap(model, X, nb_classes, batch_size, num_input_channels, ratio):\n",
    "    \"\"\"\n",
    "    To get heat map from the weight present in last convolutional layer in VGGCAM network\n",
    "    \"\"\"\n",
    "    inc = model.layers[0].input\n",
    "    conv6 = model.layers[-4].output\n",
    "    conv6_resized = absconv.bilinear_upsampling(conv6, ratio,\n",
    "                                                batch_size=batch_size,\n",
    "                                                num_input_channels=num_input_channels)\n",
    "    WT = model.layers[-1].W.T\n",
    "    conv6_resized = K.reshape(conv6_resized, (1, -1, 224 * 224))\n",
    "    classmap = K.dot(WT, conv6_resized)\n",
    "#     print \"\\n\"+\"$\"*50\n",
    "    classmap = classmap.reshape((1, nb_classes, 224, 224))\n",
    "    get_cmap = K.function([inc], classmap)\n",
    "    return get_cmap([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_classmap(VGGCAM_weight_path, trainedModel,img_path, label,\n",
    "                  nb_classes, num_input_channels, ratio=16):\n",
    "    \"\"\"\n",
    "    Plot class activation map of trained VGGCAM model\n",
    "    args: VGGCAM_weight_path (str) path to trained keras VGGCAM weights\n",
    "          img_path (str) path to the image for which we get the activation map\n",
    "          label (int) label (0 to nb_classes-1) of the class activation map to plot\n",
    "          nb_classes (int) number of classes\n",
    "          num_input_channels (int) number of conv filters to add\n",
    "                                   in before the GAP layer\n",
    "          ratio (int) upsampling ratio (16 * 14 = 224)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and compile model\n",
    "    modelCAM = VGGCAM(nb_classes, num_input_channels)\n",
    "    modelCAM.load_weights(VGGCAM_weight_path)\n",
    "    modelCAM.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\")\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    #vgg model is used to predict class\n",
    "    label =  trainedModel.predict_classes(x.reshape(1, 3, 224, 224),verbose=0)\n",
    "\n",
    "    batch_size = 1\n",
    "    classmap = get_classmap(modelCAM,\n",
    "                            x.reshape(1, 3, 224, 224),\n",
    "                            nb_classes,\n",
    "                            batch_size,\n",
    "                            num_input_channels=num_input_channels,\n",
    "                            ratio=ratio)\n",
    "    classes = [\"jeans\",\"tshirt\"]\n",
    "    print \"PREDICTED LABEL : \", classes[label[0]]\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    #mapping activation on the basis of weights\n",
    "    activation = classmap[0,0, :, :]+classmap[0,1, :, :]\n",
    "    plt.imshow(activation,\n",
    "               cmap='jet',\n",
    "               alpha=0.5,\n",
    "               interpolation='nearest')\n",
    "    plt.show()\n",
    "#     plt.imsave(VGGCAM_weight_path+\".jpg\",classmap[0, label, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train and test on the go\n",
    "num_input_channels = 1024\n",
    "epoches =25\n",
    "batchSize = 14000\n",
    "train_VGGCAM(\"vgg16_weights.h5\",2,epoches,batchSize, num_input_channels = num_input_channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
